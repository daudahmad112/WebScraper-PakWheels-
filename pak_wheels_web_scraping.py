# -*- coding: utf-8 -*-
"""Pak Wheels Web Scraping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jYKLqbhV1GPBa67u_qMymZZm-rbqf4PF
"""

from bs4 import BeautifulSoup
import requests
import pandas as pd
import numpy as np

url = 'https://www.pakwheels.com/used-cars/search/-/ct_islamabad/?q=prius&page=1'
page = requests.get(url)
print(page)

soup = BeautifulSoup(page.text,'html.parser')
soup = BeautifulSoup(soup.prettify())
print(soup)

containers = soup.find_all('div', class_='col-md-9 grid-style')

PakWheels = []
Info=[]
BetterDF = []
for container in containers:
  title = container.find('h3').text.strip()
  price = container.find('div',class_='price-details generic-dark-grey').text.strip().replace('\n', '')

  ## Ahead for Vehicle Info ##

  ul = container.find('ul',class_='list-unstyled search-vehicle-info-2 fs13')
  li = ul.find_all('li')
  Year = li[0].text.strip()
  Mileage = li[1].text.strip()
  Fuel = li[2].text.strip()
  HP = li[3].text.strip()
  Transmission = li[4].text.strip()

  ## END VEHICLE INFO

  ## Add Link Too
  link = container.find('a',class_='car-name ad-detail-path')['href']
  link = 'https://www.pakwheels.com'+link


  Info.append([Year, Mileage, Fuel, HP, Transmission])
  PakWheels.append([title, price, Info])
  BetterDF.append([title, price, Year, Mileage, Fuel, HP, Transmission, link]) ## Only NEED THIS

#  print('TITLE',title,'| Price',price,'| Year',Year, '| Mileage',Mileage, '| Fuel', Fuel, '| HP', HP, '| Transmission', Transmission)

#  print(title,price)

print(BetterDF)

#df1 = pd.DataFrame (PakWheels, columns = ['TITLE','PRICE','Info'])#'Year', 'Mileage','Fuel Type', 'Horsepower','Transmission'])
df2 = pd.DataFrame (BetterDF, columns = ['TITLE','PRICE','Year', 'Mileage','Fuel Type', 'Horsepower','Transmission','Link'])
df2

df2.to_csv(r'PakWheels.csv', index= False)

# NOW MULTIPLE PAGES
BetterDF = []
for i in range(1,150):
  print(f'page number is {i}')
  url         = f'https://www.pakwheels.com/used-cars/search/-/ct_islamabad/?q=prius&page={i}'
  page        = requests.get(url)
  soup        = BeautifulSoup(page.text,'html.parser')
  soup        = BeautifulSoup(soup.prettify())
  containers  = soup.find_all('div', class_='col-md-9 grid-style')

  for container in containers:
    title     = container.find('h3').text.strip()
    price     = container.find('div',class_='price-details generic-dark-grey').text.strip().replace('\n', '')

    ## Ahead for Vehicle Info ##

    ul           = container.find('ul',class_='list-unstyled search-vehicle-info-2 fs13')
    li           = ul.find_all('li')
    Year         = li[0].text.strip()
    Mileage      = li[1].text.strip()
    Fuel         = li[2].text.strip()
    HP           = li[3].text.strip()
    Transmission = li[4].text.strip()

    ## END VEHICLE INFO

    ## Add Link Too
    link = container.find('a',class_='car-name ad-detail-path')['href']
    link = 'https://www.pakwheels.com'+link

    page = 'page ' + str(i)

    BetterDF.append([title, price, Year, Mileage, Fuel, HP, Transmission, page, link]) ## Only NEED THIS


df2 = pd.DataFrame (BetterDF, columns = ['TITLE','PRICE','Year', 'Mileage','Fuel Type', 'Horsepower','Transmission','Page','Link'])

df2.to_csv(r'PakWheels 16 June.csv', index= False)

pd.read_csv('PakWheels 16 June.csv')